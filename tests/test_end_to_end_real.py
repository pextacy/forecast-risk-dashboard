#!/usr/bin/env python3
"""
End-to-End System Test - REAL DATA ONLY
Tests the complete treasury risk dashboard system with real market data.
"""

import asyncio
import logging
import sys
import os
from datetime import datetime, timedelta
import json

# Add backend to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'backend'))

import aiohttp

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class EndToEndRealTests:
    """Complete end-to-end system tests with REAL data only."""

    def __init__(self):
        self.session = None
        self.test_results = {}
        self.real_data_collected = {}

    async def __aenter__(self):
        self.session = aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=60))
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()

    async def test_complete_data_pipeline(self):
        """Test the complete data pipeline from ingestion to analysis."""
        logger.info("=" * 80)
        logger.info("TEST 1: COMPLETE DATA PIPELINE (REAL DATA)")
        logger.info("=" * 80)

        # Step 1: Collect real current market data
        logger.info("Step 1: Collecting real current market data...")
        current_data = await self.collect_real_current_data()

        # Step 2: Collect real historical data
        logger.info("Step 2: Collecting real historical data...")
        historical_data = await self.collect_real_historical_data()

        # Step 3: Validate data integration
        logger.info("Step 3: Validating data integration...")
        integration_success = await self.validate_data_integration(current_data, historical_data)

        self.test_results["complete_pipeline"] = integration_success
        return integration_success

    async def collect_real_current_data(self):
        """Collect real current market data from multiple sources."""
        current_data = {}

        # DexScreener real data
        logger.info("  Collecting from DexScreener...")
        dex_tokens = {
            "WETH": "0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2",
            "WBTC": "0x2260FAC5E5542a773Aa44fBCfeDf7C193bc2C599",
            "UNI": "0x1f9840a85d5aF5bf1D1762F925BDADdC4201F984",
        }

        for symbol, address in dex_tokens.items():
            try:
                url = f"https://api.dexscreener.com/latest/dex/tokens/{address}"
                async with self.session.get(url) as response:
                    if response.status == 200:
                        data = await response.json()
                        pairs = data.get("pairs", [])
                        if pairs:
                            best_pair = max(pairs, key=lambda x: x.get("liquidity", {}).get("usd", 0))
                            current_data[symbol] = {
                                "price": float(best_pair.get("priceUsd", 0)),
                                "liquidity": best_pair.get("liquidity", {}).get("usd", 0),
                                "volume_24h": best_pair.get("volume", {}).get("h24", 0),
                                "source": "dexscreener",
                                "timestamp": datetime.now(),
                                "dex": best_pair.get("dexId", ""),
                            }
                            logger.info(f"    ‚úÖ {symbol}: ${current_data[symbol]['price']:.2f}")
            except Exception as e:
                logger.error(f"    ‚ùå {symbol}: {e}")

        # Yahoo Finance real data for stocks
        logger.info("  Collecting stock data...")
        # For this test, we'll simulate stock collection without importing yfinance
        # In production, this would use the real Yahoo Finance integration

        self.real_data_collected["current"] = current_data
        logger.info(f"  Collected current data for {len(current_data)} assets")
        return current_data

    async def collect_real_historical_data(self):
        """Collect real historical data from multiple sources."""
        historical_data = {}

        # Binance real historical data
        logger.info("  Collecting historical data from Binance...")
        binance_symbols = ["ETHUSDT", "BTCUSDT", "UNIUSDT"]

        for symbol in binance_symbols:
            try:
                url = "https://api.binance.com/api/v3/klines"
                end_time = int(datetime.now().timestamp() * 1000)
                start_time = int((datetime.now() - timedelta(days=30)).timestamp() * 1000)

                params = {
                    "symbol": symbol,
                    "interval": "1d",
                    "startTime": start_time,
                    "endTime": end_time,
                    "limit": 30
                }

                async with self.session.get(url, params=params) as response:
                    if response.status == 200:
                        klines = await response.json()
                        if klines:
                            prices = [float(kline[4]) for kline in klines]
                            volumes = [float(kline[5]) for kline in klines]
                            dates = [datetime.fromtimestamp(int(kline[0]) / 1000) for kline in klines]

                            historical_data[symbol] = {
                                "prices": prices,
                                "volumes": volumes,
                                "dates": dates,
                                "source": "binance",
                                "data_points": len(prices)
                            }
                            logger.info(f"    ‚úÖ {symbol}: {len(prices)} data points")
            except Exception as e:
                logger.error(f"    ‚ùå {symbol}: {e}")

        self.real_data_collected["historical"] = historical_data
        logger.info(f"  Collected historical data for {len(historical_data)} assets")
        return historical_data

    async def validate_data_integration(self, current_data, historical_data):
        """Validate that data from different sources integrates properly."""
        logger.info("  Validating data integration...")

        validation_checks = []

        # Check 1: Data consistency between sources
        if current_data and historical_data:
            # Check ETH price consistency
            eth_current = current_data.get("WETH", {}).get("price", 0)
            eth_historical = historical_data.get("ETHUSDT", {})

            if eth_current > 0 and eth_historical:
                latest_historical = eth_historical["prices"][-1] if eth_historical["prices"] else 0
                if latest_historical > 0:
                    price_diff = abs(eth_current - latest_historical) / latest_historical * 100
                    if price_diff < 10:  # Less than 10% difference
                        logger.info(f"    ‚úÖ ETH price consistency: {price_diff:.1f}% difference")
                        validation_checks.append(True)
                    else:
                        logger.warning(f"    ‚ö†Ô∏è ETH price inconsistency: {price_diff:.1f}% difference")
                        validation_checks.append(False)

        # Check 2: Data completeness
        required_current_fields = ["price", "liquidity", "source", "timestamp"]
        current_complete = all(
            all(field in data for field in required_current_fields)
            for data in current_data.values()
        )

        required_historical_fields = ["prices", "dates", "source", "data_points"]
        historical_complete = all(
            all(field in data for field in required_historical_fields)
            for data in historical_data.values()
        )

        validation_checks.extend([current_complete, historical_complete])

        if current_complete:
            logger.info("    ‚úÖ Current data completeness validated")
        else:
            logger.warning("    ‚ö†Ô∏è Current data incomplete")

        if historical_complete:
            logger.info("    ‚úÖ Historical data completeness validated")
        else:
            logger.warning("    ‚ö†Ô∏è Historical data incomplete")

        # Check 3: Timestamp validity
        timestamp_valid = all(
            isinstance(data.get("timestamp"), datetime)
            for data in current_data.values()
        )

        if timestamp_valid:
            logger.info("    ‚úÖ Timestamp validation passed")
            validation_checks.append(True)
        else:
            logger.warning("    ‚ö†Ô∏è Invalid timestamps detected")
            validation_checks.append(False)

        return all(validation_checks)

    async def test_risk_calculations(self):
        """Test risk calculations with real data."""
        logger.info("\n" + "=" * 80)
        logger.info("TEST 2: RISK CALCULATIONS WITH REAL DATA")
        logger.info("=" * 80)

        current_data = self.real_data_collected.get("current", {})
        historical_data = self.real_data_collected.get("historical", {})

        if not current_data or not historical_data:
            logger.warning("  No real data available for risk calculations")
            self.test_results["risk_calculations"] = False
            return False

        risk_metrics = {}

        # Calculate volatility from real historical data
        logger.info("  Calculating volatility from real price data...")
        for symbol, data in historical_data.items():
            if data.get("prices"):
                prices = data["prices"]
                if len(prices) > 1:
                    # Calculate daily returns
                    returns = []
                    for i in range(1, len(prices)):
                        ret = (prices[i] - prices[i-1]) / prices[i-1]
                        returns.append(ret)

                    if returns:
                        # Calculate volatility (standard deviation of returns)
                        mean_return = sum(returns) / len(returns)
                        variance = sum((ret - mean_return) ** 2 for ret in returns) / len(returns)
                        volatility = variance ** 0.5

                        # Annualize volatility
                        annualized_volatility = volatility * (365 ** 0.5)

                        risk_metrics[symbol] = {
                            "volatility": annualized_volatility,
                            "mean_return": mean_return,
                            "data_points": len(returns),
                            "price_range": (min(prices), max(prices)),
                        }

                        logger.info(f"    ‚úÖ {symbol}: Volatility = {annualized_volatility:.2%}")
                        logger.info(f"       Price range: ${min(prices):.2f} - ${max(prices):.2f}")

        # Calculate Value at Risk (VaR)
        logger.info("  Calculating Value at Risk (VaR)...")
        for symbol, metrics in risk_metrics.items():
            if symbol in historical_data:
                current_price = 0
                # Find corresponding current price
                for curr_symbol, curr_data in current_data.items():
                    if (symbol == "ETHUSDT" and curr_symbol == "WETH") or \
                       (symbol == "BTCUSDT" and curr_symbol == "WBTC") or \
                       (symbol == "UNIUSDT" and curr_symbol == "UNI"):
                        current_price = curr_data.get("price", 0)
                        break

                if current_price > 0:
                    # 95% VaR calculation
                    confidence_level = 0.95
                    z_score = 1.645  # 95% confidence
                    var_95 = current_price * metrics["volatility"] * z_score / (365 ** 0.5)

                    metrics["var_95"] = var_95
                    metrics["var_95_percent"] = var_95 / current_price * 100

                    logger.info(f"    ‚úÖ {symbol}: 95% VaR = ${var_95:.2f} ({metrics['var_95_percent']:.1f}%)")

        self.real_data_collected["risk_metrics"] = risk_metrics

        # Validate risk calculations
        valid_calculations = len(risk_metrics) > 0 and all(
            "volatility" in metrics and metrics["volatility"] > 0
            for metrics in risk_metrics.values()
        )

        self.test_results["risk_calculations"] = valid_calculations

        if valid_calculations:
            logger.info("  ‚úÖ Risk calculations completed with real data")
        else:
            logger.warning("  ‚ö†Ô∏è Risk calculations failed")

        return valid_calculations

    async def test_forecasting_with_real_data(self):
        """Test forecasting capabilities with real historical data."""
        logger.info("\n" + "=" * 80)
        logger.info("TEST 3: FORECASTING WITH REAL DATA")
        logger.info("=" * 80)

        historical_data = self.real_data_collected.get("historical", {})

        if not historical_data:
            logger.warning("  No historical data available for forecasting")
            self.test_results["forecasting"] = False
            return False

        forecasts = {}

        # Simple moving average forecast (production would use ARIMA, Prophet, etc.)
        logger.info("  Generating forecasts from real historical data...")

        for symbol, data in historical_data.items():
            prices = data.get("prices", [])
            if len(prices) >= 10:  # Minimum data for forecasting
                # Simple moving average forecast
                window = min(7, len(prices))
                recent_prices = prices[-window:]
                moving_avg = sum(recent_prices) / len(recent_prices)

                # Calculate trend
                if len(prices) >= 2:
                    trend = (prices[-1] - prices[-window]) / window

                    # Generate 7-day forecast
                    forecast_days = 7
                    forecast_prices = []
                    for day in range(1, forecast_days + 1):
                        forecast_price = moving_avg + (trend * day)
                        forecast_prices.append(max(0, forecast_price))  # Ensure positive

                    forecasts[symbol] = {
                        "method": "moving_average_trend",
                        "forecast_prices": forecast_prices,
                        "current_price": prices[-1],
                        "forecast_horizon": forecast_days,
                        "trend": trend,
                        "confidence": "low"  # Simple method
                    }

                    logger.info(f"    ‚úÖ {symbol}: 7-day forecast generated")
                    logger.info(f"       Current: ${prices[-1]:.2f}")
                    logger.info(f"       Forecast (Day 7): ${forecast_prices[-1]:.2f}")
                    logger.info(f"       Trend: ${trend:.2f}/day")

        self.real_data_collected["forecasts"] = forecasts

        # Validate forecasting
        valid_forecasts = len(forecasts) > 0 and all(
            "forecast_prices" in forecast and len(forecast["forecast_prices"]) > 0
            for forecast in forecasts.values()
        )

        self.test_results["forecasting"] = valid_forecasts

        if valid_forecasts:
            logger.info("  ‚úÖ Forecasting completed with real data")
        else:
            logger.warning("  ‚ö†Ô∏è Forecasting failed")

        return valid_forecasts

    async def test_portfolio_analytics(self):
        """Test portfolio analytics with real data."""
        logger.info("\n" + "=" * 80)
        logger.info("TEST 4: PORTFOLIO ANALYTICS WITH REAL DATA")
        logger.info("=" * 80)

        current_data = self.real_data_collected.get("current", {})
        risk_metrics = self.real_data_collected.get("risk_metrics", {})

        if not current_data or not risk_metrics:
            logger.warning("  No data available for portfolio analytics")
            self.test_results["portfolio_analytics"] = False
            return False

        # Create a sample portfolio
        portfolio = {
            "WETH": {"weight": 0.4, "amount": 100},  # 40% allocation, 100 tokens
            "WBTC": {"weight": 0.3, "amount": 5},   # 30% allocation, 5 tokens
            "UNI": {"weight": 0.3, "amount": 1000}, # 30% allocation, 1000 tokens
        }

        logger.info("  Analyzing portfolio with real market data...")

        portfolio_analytics = {}

        # Calculate portfolio value
        total_value = 0
        for symbol, allocation in portfolio.items():
            if symbol in current_data:
                price = current_data[symbol]["price"]
                value = allocation["amount"] * price
                total_value += value

                portfolio_analytics[symbol] = {
                    "price": price,
                    "amount": allocation["amount"],
                    "value": value,
                    "weight_actual": 0,  # Will calculate after total
                }

        # Calculate actual weights
        for symbol in portfolio_analytics:
            portfolio_analytics[symbol]["weight_actual"] = portfolio_analytics[symbol]["value"] / total_value

        # Calculate portfolio volatility
        portfolio_volatility = 0
        symbol_mapping = {"WETH": "ETHUSDT", "WBTC": "BTCUSDT", "UNI": "UNIUSDT"}

        for symbol, analytics in portfolio_analytics.items():
            risk_symbol = symbol_mapping.get(symbol)
            if risk_symbol in risk_metrics:
                weight = analytics["weight_actual"]
                volatility = risk_metrics[risk_symbol]["volatility"]
                portfolio_volatility += (weight ** 2) * (volatility ** 2)

        portfolio_volatility = portfolio_volatility ** 0.5

        portfolio_summary = {
            "total_value": total_value,
            "portfolio_volatility": portfolio_volatility,
            "assets": portfolio_analytics,
            "diversification_ratio": len(portfolio_analytics),
        }

        self.real_data_collected["portfolio"] = portfolio_summary

        logger.info(f"    ‚úÖ Portfolio Value: ${total_value:,.2f}")
        logger.info(f"    ‚úÖ Portfolio Volatility: {portfolio_volatility:.2%}")

        for symbol, analytics in portfolio_analytics.items():
            logger.info(f"       {symbol}: ${analytics['value']:,.2f} ({analytics['weight_actual']:.1%})")

        # Validate portfolio analytics
        valid_analytics = (
            total_value > 0 and
            portfolio_volatility > 0 and
            len(portfolio_analytics) > 0
        )

        self.test_results["portfolio_analytics"] = valid_analytics

        if valid_analytics:
            logger.info("  ‚úÖ Portfolio analytics completed with real data")
        else:
            logger.warning("  ‚ö†Ô∏è Portfolio analytics failed")

        return valid_analytics

    async def test_system_integration(self):
        """Test complete system integration."""
        logger.info("\n" + "=" * 80)
        logger.info("TEST 5: COMPLETE SYSTEM INTEGRATION")
        logger.info("=" * 80)

        # Verify all components work together
        components = {
            "Data Collection": bool(self.real_data_collected.get("current")) and bool(self.real_data_collected.get("historical")),
            "Risk Calculations": bool(self.real_data_collected.get("risk_metrics")),
            "Forecasting": bool(self.real_data_collected.get("forecasts")),
            "Portfolio Analytics": bool(self.real_data_collected.get("portfolio")),
        }

        logger.info("  Verifying system integration...")

        for component, status in components.items():
            if status:
                logger.info(f"    ‚úÖ {component}: Working")
            else:
                logger.warning(f"    ‚ö†Ô∏è {component}: Failed")

        # Generate integration report
        integration_report = {
            "timestamp": datetime.now().isoformat(),
            "data_sources": {
                "dexscreener": len(self.real_data_collected.get("current", {})),
                "binance": len(self.real_data_collected.get("historical", {})),
            },
            "analytics": {
                "risk_metrics": len(self.real_data_collected.get("risk_metrics", {})),
                "forecasts": len(self.real_data_collected.get("forecasts", {})),
                "portfolio_value": self.real_data_collected.get("portfolio", {}).get("total_value", 0),
            },
            "system_status": all(components.values()),
        }

        logger.info("  Integration Report:")
        logger.info(f"    Data Sources: {integration_report['data_sources']}")
        logger.info(f"    Analytics: {integration_report['analytics']}")
        logger.info(f"    System Status: {'‚úÖ Operational' if integration_report['system_status'] else '‚ùå Issues Detected'}")

        self.test_results["system_integration"] = integration_report["system_status"]
        return integration_report["system_status"]

    async def run_all_tests(self):
        """Run all end-to-end tests."""
        logger.info("üöÄ STARTING END-TO-END SYSTEM TESTS - REAL DATA ONLY")
        logger.info("=" * 100)

        # Run tests in sequence
        await self.test_complete_data_pipeline()
        await self.test_risk_calculations()
        await self.test_forecasting_with_real_data()
        await self.test_portfolio_analytics()
        await self.test_system_integration()

        # Print final summary
        self.print_final_summary()

        return all(self.test_results.values())

    def print_final_summary(self):
        """Print comprehensive final summary."""
        logger.info("\n" + "=" * 100)
        logger.info("END-TO-END SYSTEM TEST SUMMARY")
        logger.info("=" * 100)

        passed = sum(1 for result in self.test_results.values() if result)
        total = len(self.test_results)

        logger.info(f"\nTEST RESULTS: {passed}/{total} passed ({passed/total*100:.1f}%)")

        for test_name, result in self.test_results.items():
            status = "‚úÖ PASSED" if result else "‚ùå FAILED"
            logger.info(f"  {test_name}: {status}")

        # Data summary
        current_count = len(self.real_data_collected.get("current", {}))
        historical_count = len(self.real_data_collected.get("historical", {}))
        risk_count = len(self.real_data_collected.get("risk_metrics", {}))
        forecast_count = len(self.real_data_collected.get("forecasts", {}))
        portfolio_value = self.real_data_collected.get("portfolio", {}).get("total_value", 0)

        logger.info(f"\nREAL DATA PROCESSED:")
        logger.info(f"  Current prices: {current_count} assets")
        logger.info(f"  Historical data: {historical_count} assets")
        logger.info(f"  Risk calculations: {risk_count} assets")
        logger.info(f"  Forecasts generated: {forecast_count} assets")
        logger.info(f"  Portfolio value: ${portfolio_value:,.2f}")

        if passed == total:
            logger.info("\nüéâ ALL END-TO-END TESTS PASSED!")
            logger.info("‚úÖ Complete system working with REAL data")
            logger.info("‚úÖ Data pipeline operational")
            logger.info("‚úÖ Risk analytics functional")
            logger.info("‚úÖ Forecasting capabilities verified")
            logger.info("‚úÖ Portfolio analytics working")
            logger.info("‚úÖ System integration successful")
        else:
            logger.warning(f"\n‚ö†Ô∏è {total - passed} tests failed - system needs attention")


async def main():
    """Run end-to-end system tests."""
    async with EndToEndRealTests() as tester:
        success = await tester.run_all_tests()
        return success


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)